{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package import\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# for clustered heatmap creation\n",
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "# for finding the MAD and IQR of ranges\n",
    "import scipy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Dataset\n",
    "The dataset has 388 records which are represented as anonymized as patient barcodes beginning with \"GSM...\" The first four rows contains patient metadata such as gender and ethnicity. There are 32050 features in this dataset which is much fewer than the most modern assay datasets. Each feature is represented as an Illumina transcript ID starting with \"ILMN...\" All assays were performed on the patients' blood. By default, array datasets have records as columns and features as rows. This is because there are often many many more features than samples in bioinformatics datasets. For our analyses using Scikit-Learn and Scipy models, we will need to transpose the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32053, 390)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probe_ID</th>\n",
       "      <th>Patient_barcode</th>\n",
       "      <th>GSM1539409</th>\n",
       "      <th>GSM1539410</th>\n",
       "      <th>GSM1539411</th>\n",
       "      <th>GSM1539412</th>\n",
       "      <th>GSM1539413</th>\n",
       "      <th>GSM1539414</th>\n",
       "      <th>GSM1539415</th>\n",
       "      <th>GSM1539416</th>\n",
       "      <th>...</th>\n",
       "      <th>GSM1539787</th>\n",
       "      <th>GSM1539788</th>\n",
       "      <th>GSM1539789</th>\n",
       "      <th>GSM1539790</th>\n",
       "      <th>GSM1539791</th>\n",
       "      <th>GSM1539792</th>\n",
       "      <th>GSM1539793</th>\n",
       "      <th>GSM1539794</th>\n",
       "      <th>GSM1539795</th>\n",
       "      <th>GSM1539796</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Sex</td>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>Male</td>\n",
       "      <td>Male</td>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>Male</td>\n",
       "      <td>Female</td>\n",
       "      <td>Female</td>\n",
       "      <td>Male</td>\n",
       "      <td>Male</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Condition</td>\n",
       "      <td>MCI</td>\n",
       "      <td>MCI</td>\n",
       "      <td>MCI</td>\n",
       "      <td>MCI</td>\n",
       "      <td>MCI</td>\n",
       "      <td>MCI</td>\n",
       "      <td>MCI</td>\n",
       "      <td>MCI</td>\n",
       "      <td>...</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD</td>\n",
       "      <td>MCI</td>\n",
       "      <td>MCI</td>\n",
       "      <td>MCI</td>\n",
       "      <td>MCI</td>\n",
       "      <td>MCI</td>\n",
       "      <td>AD</td>\n",
       "      <td>CTL</td>\n",
       "      <td>CTL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ethnicity</td>\n",
       "      <td>Western European</td>\n",
       "      <td>Western European</td>\n",
       "      <td>Western European</td>\n",
       "      <td>Western European</td>\n",
       "      <td>Other Caucasian</td>\n",
       "      <td>Other Caucasian</td>\n",
       "      <td>Western European</td>\n",
       "      <td>Any_Other_White_Background</td>\n",
       "      <td>...</td>\n",
       "      <td>Western European</td>\n",
       "      <td>British_English</td>\n",
       "      <td>unkown but she's white and speaks english with...</td>\n",
       "      <td>Western European</td>\n",
       "      <td>British</td>\n",
       "      <td>Western European</td>\n",
       "      <td>Western European</td>\n",
       "      <td>Western European</td>\n",
       "      <td>Western European</td>\n",
       "      <td>British_English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Age</td>\n",
       "      <td>57</td>\n",
       "      <td>59</td>\n",
       "      <td>63</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>...</td>\n",
       "      <td>79</td>\n",
       "      <td>73</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>86</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>82</td>\n",
       "      <td>88</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ILMN_1343291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.55280722</td>\n",
       "      <td>12.71145907</td>\n",
       "      <td>13.08839335</td>\n",
       "      <td>12.64383051</td>\n",
       "      <td>13.09838903</td>\n",
       "      <td>13.08609968</td>\n",
       "      <td>13.40034321</td>\n",
       "      <td>12.97418372</td>\n",
       "      <td>...</td>\n",
       "      <td>12.98168176</td>\n",
       "      <td>13.63916729</td>\n",
       "      <td>12.9214465</td>\n",
       "      <td>13.2494056</td>\n",
       "      <td>13.5265911</td>\n",
       "      <td>12.31184583</td>\n",
       "      <td>13.22532792</td>\n",
       "      <td>12.95210419</td>\n",
       "      <td>13.16336147</td>\n",
       "      <td>13.34775027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 390 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Probe_ID Patient_barcode        GSM1539409        GSM1539410  \\\n",
       "0           NaN             Sex            Female            Female   \n",
       "1           NaN       Condition               MCI               MCI   \n",
       "2           NaN       Ethnicity  Western European  Western European   \n",
       "3           NaN             Age                57                59   \n",
       "4  ILMN_1343291             NaN       12.55280722       12.71145907   \n",
       "\n",
       "         GSM1539411        GSM1539412       GSM1539413       GSM1539414  \\\n",
       "0            Female            Female           Female           Female   \n",
       "1               MCI               MCI              MCI              MCI   \n",
       "2  Western European  Western European  Other Caucasian  Other Caucasian   \n",
       "3                63                65               66               68   \n",
       "4       13.08839335       12.64383051      13.09838903      13.08609968   \n",
       "\n",
       "         GSM1539415                  GSM1539416  ...        GSM1539787  \\\n",
       "0            Female                      Female  ...              Male   \n",
       "1               MCI                         MCI  ...                AD   \n",
       "2  Western European  Any_Other_White_Background  ...  Western European   \n",
       "3                68                          68  ...                79   \n",
       "4       13.40034321                 12.97418372  ...       12.98168176   \n",
       "\n",
       "        GSM1539788                                         GSM1539789  \\\n",
       "0             Male                                             Female   \n",
       "1               AD                                                MCI   \n",
       "2  British_English  unkown but she's white and speaks english with...   \n",
       "3               73                                                 83   \n",
       "4      13.63916729                                         12.9214465   \n",
       "\n",
       "         GSM1539790  GSM1539791        GSM1539792        GSM1539793  \\\n",
       "0            Female        Male            Female            Female   \n",
       "1               MCI         MCI               MCI               MCI   \n",
       "2  Western European     British  Western European  Western European   \n",
       "3                80          86                83                83   \n",
       "4        13.2494056  13.5265911       12.31184583       13.22532792   \n",
       "\n",
       "         GSM1539794        GSM1539795       GSM1539796  \n",
       "0              Male              Male           Female  \n",
       "1                AD               CTL              CTL  \n",
       "2  Western European  Western European  British_English  \n",
       "3                82                88               86  \n",
       "4       12.95210419       13.16336147      13.34775027  \n",
       "\n",
       "[5 rows x 390 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the dataset from file path\n",
    "data = pd.read_csv('Pre_Subset/transposed_GSE63063.csv',header= 0)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>32043</th>\n",
       "      <th>32044</th>\n",
       "      <th>32045</th>\n",
       "      <th>32046</th>\n",
       "      <th>32047</th>\n",
       "      <th>32048</th>\n",
       "      <th>32049</th>\n",
       "      <th>32050</th>\n",
       "      <th>32051</th>\n",
       "      <th>32052</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Probe_ID</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ILMN_1343291</td>\n",
       "      <td>ILMN_1343295</td>\n",
       "      <td>ILMN_1651209</td>\n",
       "      <td>ILMN_1651210</td>\n",
       "      <td>ILMN_1651221</td>\n",
       "      <td>ILMN_1651228</td>\n",
       "      <td>...</td>\n",
       "      <td>ILMN_3311110</td>\n",
       "      <td>ILMN_3311115</td>\n",
       "      <td>ILMN_3311135</td>\n",
       "      <td>ILMN_3311145</td>\n",
       "      <td>ILMN_3311150</td>\n",
       "      <td>ILMN_3311155</td>\n",
       "      <td>ILMN_3311165</td>\n",
       "      <td>ILMN_3311170</td>\n",
       "      <td>ILMN_3311180</td>\n",
       "      <td>ILMN_3311190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient_barcode</th>\n",
       "      <td>Sex</td>\n",
       "      <td>Condition</td>\n",
       "      <td>Ethnicity</td>\n",
       "      <td>Age</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1539409</th>\n",
       "      <td>Female</td>\n",
       "      <td>MCI</td>\n",
       "      <td>Western European</td>\n",
       "      <td>57</td>\n",
       "      <td>12.55280722</td>\n",
       "      <td>10.10155567</td>\n",
       "      <td>6.084670984</td>\n",
       "      <td>6.068804773</td>\n",
       "      <td>6.121059835</td>\n",
       "      <td>10.83398435</td>\n",
       "      <td>...</td>\n",
       "      <td>6.04762</td>\n",
       "      <td>6.19183</td>\n",
       "      <td>6.13272</td>\n",
       "      <td>6.16856</td>\n",
       "      <td>6.0649</td>\n",
       "      <td>6.09593</td>\n",
       "      <td>6.20084</td>\n",
       "      <td>6.00451</td>\n",
       "      <td>6.04553</td>\n",
       "      <td>6.25168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1539410</th>\n",
       "      <td>Female</td>\n",
       "      <td>MCI</td>\n",
       "      <td>Western European</td>\n",
       "      <td>59</td>\n",
       "      <td>12.71145907</td>\n",
       "      <td>9.776015081</td>\n",
       "      <td>6.255012487</td>\n",
       "      <td>6.016468162</td>\n",
       "      <td>6.173167357</td>\n",
       "      <td>10.27067251</td>\n",
       "      <td>...</td>\n",
       "      <td>6.08059</td>\n",
       "      <td>6.20489</td>\n",
       "      <td>6.03258</td>\n",
       "      <td>6.02194</td>\n",
       "      <td>6.08126</td>\n",
       "      <td>6.08884</td>\n",
       "      <td>6.39421</td>\n",
       "      <td>5.9881</td>\n",
       "      <td>6.03702</td>\n",
       "      <td>6.16483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1539411</th>\n",
       "      <td>Female</td>\n",
       "      <td>MCI</td>\n",
       "      <td>Western European</td>\n",
       "      <td>63</td>\n",
       "      <td>13.08839335</td>\n",
       "      <td>9.594397134</td>\n",
       "      <td>6.160484783</td>\n",
       "      <td>6.024321505</td>\n",
       "      <td>6.039552262</td>\n",
       "      <td>10.43059366</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0661</td>\n",
       "      <td>5.98867</td>\n",
       "      <td>6.11673</td>\n",
       "      <td>6.02284</td>\n",
       "      <td>6.04491</td>\n",
       "      <td>6.14502</td>\n",
       "      <td>6.08668</td>\n",
       "      <td>6.06621</td>\n",
       "      <td>6.09827</td>\n",
       "      <td>6.28441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32053 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0          1                 2     3             4      \\\n",
       "Probe_ID            NaN        NaN               NaN   NaN  ILMN_1343291   \n",
       "Patient_barcode     Sex  Condition         Ethnicity   Age           NaN   \n",
       "GSM1539409       Female        MCI  Western European    57   12.55280722   \n",
       "GSM1539410       Female        MCI  Western European    59   12.71145907   \n",
       "GSM1539411       Female        MCI  Western European    63   13.08839335   \n",
       "\n",
       "                        5             6             7             8      \\\n",
       "Probe_ID         ILMN_1343295  ILMN_1651209  ILMN_1651210  ILMN_1651221   \n",
       "Patient_barcode           NaN           NaN           NaN           NaN   \n",
       "GSM1539409        10.10155567   6.084670984   6.068804773   6.121059835   \n",
       "GSM1539410        9.776015081   6.255012487   6.016468162   6.173167357   \n",
       "GSM1539411        9.594397134   6.160484783   6.024321505   6.039552262   \n",
       "\n",
       "                        9      ...         32043         32044         32045  \\\n",
       "Probe_ID         ILMN_1651228  ...  ILMN_3311110  ILMN_3311115  ILMN_3311135   \n",
       "Patient_barcode           NaN  ...           NaN           NaN           NaN   \n",
       "GSM1539409        10.83398435  ...       6.04762       6.19183       6.13272   \n",
       "GSM1539410        10.27067251  ...       6.08059       6.20489       6.03258   \n",
       "GSM1539411        10.43059366  ...        6.0661       5.98867       6.11673   \n",
       "\n",
       "                        32046         32047         32048         32049  \\\n",
       "Probe_ID         ILMN_3311145  ILMN_3311150  ILMN_3311155  ILMN_3311165   \n",
       "Patient_barcode           NaN           NaN           NaN           NaN   \n",
       "GSM1539409            6.16856        6.0649       6.09593       6.20084   \n",
       "GSM1539410            6.02194       6.08126       6.08884       6.39421   \n",
       "GSM1539411            6.02284       6.04491       6.14502       6.08668   \n",
       "\n",
       "                        32050         32051         32052  \n",
       "Probe_ID         ILMN_3311170  ILMN_3311180  ILMN_3311190  \n",
       "Patient_barcode           NaN           NaN           NaN  \n",
       "GSM1539409            6.00451       6.04553       6.25168  \n",
       "GSM1539410             5.9881       6.03702       6.16483  \n",
       "GSM1539411            6.06621       6.09827       6.28441  \n",
       "\n",
       "[5 rows x 32053 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose the data such that rows and columns are flipped\n",
    "data = data.T\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(389, 32049)\n",
      "(388,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>...</th>\n",
       "      <th>32043</th>\n",
       "      <th>32044</th>\n",
       "      <th>32045</th>\n",
       "      <th>32046</th>\n",
       "      <th>32047</th>\n",
       "      <th>32048</th>\n",
       "      <th>32049</th>\n",
       "      <th>32050</th>\n",
       "      <th>32051</th>\n",
       "      <th>32052</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Probe_ID</th>\n",
       "      <td>ILMN_1343291</td>\n",
       "      <td>ILMN_1343295</td>\n",
       "      <td>ILMN_1651209</td>\n",
       "      <td>ILMN_1651210</td>\n",
       "      <td>ILMN_1651221</td>\n",
       "      <td>ILMN_1651228</td>\n",
       "      <td>ILMN_1651229</td>\n",
       "      <td>ILMN_1651235</td>\n",
       "      <td>ILMN_1651237</td>\n",
       "      <td>ILMN_1651254</td>\n",
       "      <td>...</td>\n",
       "      <td>ILMN_3311110</td>\n",
       "      <td>ILMN_3311115</td>\n",
       "      <td>ILMN_3311135</td>\n",
       "      <td>ILMN_3311145</td>\n",
       "      <td>ILMN_3311150</td>\n",
       "      <td>ILMN_3311155</td>\n",
       "      <td>ILMN_3311165</td>\n",
       "      <td>ILMN_3311170</td>\n",
       "      <td>ILMN_3311180</td>\n",
       "      <td>ILMN_3311190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1539409</th>\n",
       "      <td>12.55280722</td>\n",
       "      <td>10.10155567</td>\n",
       "      <td>6.084670984</td>\n",
       "      <td>6.068804773</td>\n",
       "      <td>6.121059835</td>\n",
       "      <td>10.83398435</td>\n",
       "      <td>6.61714565</td>\n",
       "      <td>6.126975706</td>\n",
       "      <td>6.062613209</td>\n",
       "      <td>9.271763244</td>\n",
       "      <td>...</td>\n",
       "      <td>6.04762</td>\n",
       "      <td>6.19183</td>\n",
       "      <td>6.13272</td>\n",
       "      <td>6.16856</td>\n",
       "      <td>6.0649</td>\n",
       "      <td>6.09593</td>\n",
       "      <td>6.20084</td>\n",
       "      <td>6.00451</td>\n",
       "      <td>6.04553</td>\n",
       "      <td>6.25168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1539410</th>\n",
       "      <td>12.71145907</td>\n",
       "      <td>9.776015081</td>\n",
       "      <td>6.255012487</td>\n",
       "      <td>6.016468162</td>\n",
       "      <td>6.173167357</td>\n",
       "      <td>10.27067251</td>\n",
       "      <td>6.590062459</td>\n",
       "      <td>6.081223364</td>\n",
       "      <td>6.013171425</td>\n",
       "      <td>9.038844778</td>\n",
       "      <td>...</td>\n",
       "      <td>6.08059</td>\n",
       "      <td>6.20489</td>\n",
       "      <td>6.03258</td>\n",
       "      <td>6.02194</td>\n",
       "      <td>6.08126</td>\n",
       "      <td>6.08884</td>\n",
       "      <td>6.39421</td>\n",
       "      <td>5.9881</td>\n",
       "      <td>6.03702</td>\n",
       "      <td>6.16483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1539411</th>\n",
       "      <td>13.08839335</td>\n",
       "      <td>9.594397134</td>\n",
       "      <td>6.160484783</td>\n",
       "      <td>6.024321505</td>\n",
       "      <td>6.039552262</td>\n",
       "      <td>10.43059366</td>\n",
       "      <td>6.509477482</td>\n",
       "      <td>6.08179111</td>\n",
       "      <td>6.012163113</td>\n",
       "      <td>9.059376238</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0661</td>\n",
       "      <td>5.98867</td>\n",
       "      <td>6.11673</td>\n",
       "      <td>6.02284</td>\n",
       "      <td>6.04491</td>\n",
       "      <td>6.14502</td>\n",
       "      <td>6.08668</td>\n",
       "      <td>6.06621</td>\n",
       "      <td>6.09827</td>\n",
       "      <td>6.28441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1539412</th>\n",
       "      <td>12.64383051</td>\n",
       "      <td>10.12678192</td>\n",
       "      <td>6.109219418</td>\n",
       "      <td>6.016117533</td>\n",
       "      <td>6.111306417</td>\n",
       "      <td>10.76520671</td>\n",
       "      <td>6.570108481</td>\n",
       "      <td>6.075929967</td>\n",
       "      <td>6.04603005</td>\n",
       "      <td>9.080948531</td>\n",
       "      <td>...</td>\n",
       "      <td>6.15373</td>\n",
       "      <td>6.06447</td>\n",
       "      <td>6.02092</td>\n",
       "      <td>6.13735</td>\n",
       "      <td>6.03171</td>\n",
       "      <td>6.0354</td>\n",
       "      <td>6.27007</td>\n",
       "      <td>6.0053</td>\n",
       "      <td>6.03248</td>\n",
       "      <td>6.35018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   4             5             6             7      \\\n",
       "Probe_ID    ILMN_1343291  ILMN_1343295  ILMN_1651209  ILMN_1651210   \n",
       "GSM1539409   12.55280722   10.10155567   6.084670984   6.068804773   \n",
       "GSM1539410   12.71145907   9.776015081   6.255012487   6.016468162   \n",
       "GSM1539411   13.08839335   9.594397134   6.160484783   6.024321505   \n",
       "GSM1539412   12.64383051   10.12678192   6.109219418   6.016117533   \n",
       "\n",
       "                   8             9             10            11     \\\n",
       "Probe_ID    ILMN_1651221  ILMN_1651228  ILMN_1651229  ILMN_1651235   \n",
       "GSM1539409   6.121059835   10.83398435    6.61714565   6.126975706   \n",
       "GSM1539410   6.173167357   10.27067251   6.590062459   6.081223364   \n",
       "GSM1539411   6.039552262   10.43059366   6.509477482    6.08179111   \n",
       "GSM1539412   6.111306417   10.76520671   6.570108481   6.075929967   \n",
       "\n",
       "                   12            13     ...         32043         32044  \\\n",
       "Probe_ID    ILMN_1651237  ILMN_1651254  ...  ILMN_3311110  ILMN_3311115   \n",
       "GSM1539409   6.062613209   9.271763244  ...       6.04762       6.19183   \n",
       "GSM1539410   6.013171425   9.038844778  ...       6.08059       6.20489   \n",
       "GSM1539411   6.012163113   9.059376238  ...        6.0661       5.98867   \n",
       "GSM1539412    6.04603005   9.080948531  ...       6.15373       6.06447   \n",
       "\n",
       "                   32045         32046         32047         32048  \\\n",
       "Probe_ID    ILMN_3311135  ILMN_3311145  ILMN_3311150  ILMN_3311155   \n",
       "GSM1539409       6.13272       6.16856        6.0649       6.09593   \n",
       "GSM1539410       6.03258       6.02194       6.08126       6.08884   \n",
       "GSM1539411       6.11673       6.02284       6.04491       6.14502   \n",
       "GSM1539412       6.02092       6.13735       6.03171        6.0354   \n",
       "\n",
       "                   32049         32050         32051         32052  \n",
       "Probe_ID    ILMN_3311165  ILMN_3311170  ILMN_3311180  ILMN_3311190  \n",
       "GSM1539409       6.20084       6.00451       6.04553       6.25168  \n",
       "GSM1539410       6.39421        5.9881       6.03702       6.16483  \n",
       "GSM1539411       6.08668       6.06621       6.09827       6.28441  \n",
       "GSM1539412       6.27007        6.0053       6.03248       6.35018  \n",
       "\n",
       "[5 rows x 32049 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate the features from the labels\n",
    "# patient identifiers will not be taken into account in our analyses\n",
    "datax = data.drop('Patient_barcode')\n",
    "# drop patient records Sex, Ethnicity, and Age\n",
    "datax = datax.drop([0,2,3],axis=1)\n",
    "# Pass patient Condition into data_y to be labels\n",
    "datay = (data[1][2:])\n",
    "# drop the labels from datax\n",
    "datax.drop(1,inplace=True,axis=1)\n",
    "\n",
    "print(datax.shape)\n",
    "print(datay.shape)\n",
    "datax.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Probe_ID</th>\n",
       "      <th>ILMN_1343291</th>\n",
       "      <th>ILMN_1343295</th>\n",
       "      <th>ILMN_1651209</th>\n",
       "      <th>ILMN_1651210</th>\n",
       "      <th>ILMN_1651221</th>\n",
       "      <th>ILMN_1651228</th>\n",
       "      <th>ILMN_1651229</th>\n",
       "      <th>ILMN_1651235</th>\n",
       "      <th>ILMN_1651237</th>\n",
       "      <th>ILMN_1651254</th>\n",
       "      <th>...</th>\n",
       "      <th>ILMN_3311110</th>\n",
       "      <th>ILMN_3311115</th>\n",
       "      <th>ILMN_3311135</th>\n",
       "      <th>ILMN_3311145</th>\n",
       "      <th>ILMN_3311150</th>\n",
       "      <th>ILMN_3311155</th>\n",
       "      <th>ILMN_3311165</th>\n",
       "      <th>ILMN_3311170</th>\n",
       "      <th>ILMN_3311180</th>\n",
       "      <th>ILMN_3311190</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM1539409</th>\n",
       "      <td>12.55280722</td>\n",
       "      <td>10.10155567</td>\n",
       "      <td>6.084670984</td>\n",
       "      <td>6.068804773</td>\n",
       "      <td>6.121059835</td>\n",
       "      <td>10.83398435</td>\n",
       "      <td>6.61714565</td>\n",
       "      <td>6.126975706</td>\n",
       "      <td>6.062613209</td>\n",
       "      <td>9.271763244</td>\n",
       "      <td>...</td>\n",
       "      <td>6.04762</td>\n",
       "      <td>6.19183</td>\n",
       "      <td>6.13272</td>\n",
       "      <td>6.16856</td>\n",
       "      <td>6.0649</td>\n",
       "      <td>6.09593</td>\n",
       "      <td>6.20084</td>\n",
       "      <td>6.00451</td>\n",
       "      <td>6.04553</td>\n",
       "      <td>6.25168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1539410</th>\n",
       "      <td>12.71145907</td>\n",
       "      <td>9.776015081</td>\n",
       "      <td>6.255012487</td>\n",
       "      <td>6.016468162</td>\n",
       "      <td>6.173167357</td>\n",
       "      <td>10.27067251</td>\n",
       "      <td>6.590062459</td>\n",
       "      <td>6.081223364</td>\n",
       "      <td>6.013171425</td>\n",
       "      <td>9.038844778</td>\n",
       "      <td>...</td>\n",
       "      <td>6.08059</td>\n",
       "      <td>6.20489</td>\n",
       "      <td>6.03258</td>\n",
       "      <td>6.02194</td>\n",
       "      <td>6.08126</td>\n",
       "      <td>6.08884</td>\n",
       "      <td>6.39421</td>\n",
       "      <td>5.9881</td>\n",
       "      <td>6.03702</td>\n",
       "      <td>6.16483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1539411</th>\n",
       "      <td>13.08839335</td>\n",
       "      <td>9.594397134</td>\n",
       "      <td>6.160484783</td>\n",
       "      <td>6.024321505</td>\n",
       "      <td>6.039552262</td>\n",
       "      <td>10.43059366</td>\n",
       "      <td>6.509477482</td>\n",
       "      <td>6.08179111</td>\n",
       "      <td>6.012163113</td>\n",
       "      <td>9.059376238</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0661</td>\n",
       "      <td>5.98867</td>\n",
       "      <td>6.11673</td>\n",
       "      <td>6.02284</td>\n",
       "      <td>6.04491</td>\n",
       "      <td>6.14502</td>\n",
       "      <td>6.08668</td>\n",
       "      <td>6.06621</td>\n",
       "      <td>6.09827</td>\n",
       "      <td>6.28441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1539412</th>\n",
       "      <td>12.64383051</td>\n",
       "      <td>10.12678192</td>\n",
       "      <td>6.109219418</td>\n",
       "      <td>6.016117533</td>\n",
       "      <td>6.111306417</td>\n",
       "      <td>10.76520671</td>\n",
       "      <td>6.570108481</td>\n",
       "      <td>6.075929967</td>\n",
       "      <td>6.04603005</td>\n",
       "      <td>9.080948531</td>\n",
       "      <td>...</td>\n",
       "      <td>6.15373</td>\n",
       "      <td>6.06447</td>\n",
       "      <td>6.02092</td>\n",
       "      <td>6.13735</td>\n",
       "      <td>6.03171</td>\n",
       "      <td>6.0354</td>\n",
       "      <td>6.27007</td>\n",
       "      <td>6.0053</td>\n",
       "      <td>6.03248</td>\n",
       "      <td>6.35018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1539413</th>\n",
       "      <td>13.09838903</td>\n",
       "      <td>10.22330116</td>\n",
       "      <td>6.069960148</td>\n",
       "      <td>6.056163259</td>\n",
       "      <td>6.089542173</td>\n",
       "      <td>10.63234588</td>\n",
       "      <td>6.51503297</td>\n",
       "      <td>6.089808641</td>\n",
       "      <td>6.050975618</td>\n",
       "      <td>8.761323017</td>\n",
       "      <td>...</td>\n",
       "      <td>6.06107</td>\n",
       "      <td>6.07591</td>\n",
       "      <td>6.14174</td>\n",
       "      <td>6.0194</td>\n",
       "      <td>6.03691</td>\n",
       "      <td>6.05405</td>\n",
       "      <td>6.28006</td>\n",
       "      <td>6.04356</td>\n",
       "      <td>6.15125</td>\n",
       "      <td>6.19059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Probe_ID   ILMN_1343291 ILMN_1343295 ILMN_1651209 ILMN_1651210 ILMN_1651221  \\\n",
       "GSM1539409  12.55280722  10.10155567  6.084670984  6.068804773  6.121059835   \n",
       "GSM1539410  12.71145907  9.776015081  6.255012487  6.016468162  6.173167357   \n",
       "GSM1539411  13.08839335  9.594397134  6.160484783  6.024321505  6.039552262   \n",
       "GSM1539412  12.64383051  10.12678192  6.109219418  6.016117533  6.111306417   \n",
       "GSM1539413  13.09838903  10.22330116  6.069960148  6.056163259  6.089542173   \n",
       "\n",
       "Probe_ID   ILMN_1651228 ILMN_1651229 ILMN_1651235 ILMN_1651237 ILMN_1651254  \\\n",
       "GSM1539409  10.83398435   6.61714565  6.126975706  6.062613209  9.271763244   \n",
       "GSM1539410  10.27067251  6.590062459  6.081223364  6.013171425  9.038844778   \n",
       "GSM1539411  10.43059366  6.509477482   6.08179111  6.012163113  9.059376238   \n",
       "GSM1539412  10.76520671  6.570108481  6.075929967   6.04603005  9.080948531   \n",
       "GSM1539413  10.63234588   6.51503297  6.089808641  6.050975618  8.761323017   \n",
       "\n",
       "Probe_ID    ... ILMN_3311110 ILMN_3311115 ILMN_3311135 ILMN_3311145  \\\n",
       "GSM1539409  ...      6.04762      6.19183      6.13272      6.16856   \n",
       "GSM1539410  ...      6.08059      6.20489      6.03258      6.02194   \n",
       "GSM1539411  ...       6.0661      5.98867      6.11673      6.02284   \n",
       "GSM1539412  ...      6.15373      6.06447      6.02092      6.13735   \n",
       "GSM1539413  ...      6.06107      6.07591      6.14174       6.0194   \n",
       "\n",
       "Probe_ID   ILMN_3311150 ILMN_3311155 ILMN_3311165 ILMN_3311170 ILMN_3311180  \\\n",
       "GSM1539409       6.0649      6.09593      6.20084      6.00451      6.04553   \n",
       "GSM1539410      6.08126      6.08884      6.39421       5.9881      6.03702   \n",
       "GSM1539411      6.04491      6.14502      6.08668      6.06621      6.09827   \n",
       "GSM1539412      6.03171       6.0354      6.27007       6.0053      6.03248   \n",
       "GSM1539413      6.03691      6.05405      6.28006      6.04356      6.15125   \n",
       "\n",
       "Probe_ID   ILMN_3311190  \n",
       "GSM1539409      6.25168  \n",
       "GSM1539410      6.16483  \n",
       "GSM1539411      6.28441  \n",
       "GSM1539412      6.35018  \n",
       "GSM1539413      6.19059  \n",
       "\n",
       "[5 rows x 32049 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign probe ID to be column titles\n",
    "datax.columns = (datax.iloc[0])\n",
    "# drop probe ID row\n",
    "datax.drop('Probe_ID',inplace=True)\n",
    "\n",
    "datax.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "Try to determine the minimum dimensionality that would work for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Anaconda\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'MCI'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "def do_PCA (dataset, labels):   \n",
    "    #crate a scaler\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(dataset)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(scaled_data, labels, test_size=.2) \n",
    "    \n",
    "    pca = PCA(.95)\n",
    "    \n",
    "    pca_data = pca.fit_transform(X_train)\n",
    "    \n",
    "    print(pca.n_components_)\n",
    "    pca_data_df = pd.DataFrame(pca_data)\n",
    "    return(pca_data_df)\n",
    "\n",
    "def tSNE(dataset):\n",
    "    tsne = TSNE(n_components = 2)\n",
    "    \n",
    "    tsne_data = tsne.fit_transform(dataset)\n",
    "    \n",
    "\n",
    "data = do_PCA(datax , datay)\n",
    "labels = pd.DataFrame(datay)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# export datax and datay to their own .csv files to be imported as needed\n",
    "# datax.to_csv('Alzh_Features_Wrangled.csv')\n",
    "# datay.to_csv('Alzh_Labels_Wrangled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print((datax.isnull().sum()).sum(),'Missing Values in the Dataset')\n",
    "#substitute mean column values for missing values\n",
    "\n",
    "# impute empty cells with the column supplied metric (string, float, or int)\n",
    "\n",
    "def impute(dataset,metric='mean'):\n",
    "    if metric == 'mean':\n",
    "        dataset =dataset.fillna(dataset.mean(),inplace=False)\n",
    "    elif metric == 'median':\n",
    "        dataset =dataset.fillna(dataset.median(),inplace=False)\n",
    "    elif metric == 'mode':\n",
    "        dataset =dataset.fillna(dataset.mode(),inplace=False)\n",
    "    elif metric == 'zero':\n",
    "        dataset =dataset.fillna(0,inplace=False)\n",
    "    elif type(metric) == float or type(metric) == int:\n",
    "        dataset =dataset.fillna(metric,inplace=False)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts for each class:\n",
      "CTL: 134\n",
      "OTHER: 1\n",
      "CTL to AD: 1\n",
      "AD: 139\n",
      "borderline MCI: 3\n",
      "MCI: 109\n",
      "MCI to CTL: 1\n"
     ]
    }
   ],
   "source": [
    "datay_list = list(datay)\n",
    "conds = list(set(list(datay)))\n",
    "print('Counts for each class:')\n",
    "for i in conds:\n",
    "    print(\"{0}: {1}\".format(i,datay_list.count(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD = list(pd.Series.unique(datay))\n",
    "CTL = AD.copy()\n",
    "AD.remove(\"AD\")\n",
    "CTL.remove(\"CTL\")\n",
    "ADdatay = datay.replace(to_replace = AD, value = \"nonAD\")     #labels are AD and nonAD\n",
    "CTLdatay = datay.replace(to_replace = CTL, value = \"nonCTL\")  #labels are CTL and nonCTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a boxplot for every transcript\n",
    "# box_columns = datax.plot(kind='box')\n",
    "\n",
    "# box_columns.savefig('box_columns.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a genome-wide clustered heatmap with seaborn\n",
    "# this will let us look at general trends in the dataset at a macro level\n",
    "# GWHM = sns.clustermap(datax)\n",
    "# GWHM.savefig(\"GWHM.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "The Boruta algorithm is a wrapper method build around the random forest classification algorithm. The dataset is duplicated and shuffled, and the Z-scores of the real features are compared to the maximum Z-score found for the shadow features. If the Z-score of the real feature is higher, it gets flagged as important. After a pre-determined number of iterations through the dataset, any featured that hasn't been flagged gets removed. This method removes redundant variables and helps to speed up computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pandas dataframe to numpy\n",
    "X_np = datax.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define random forest classifier, with utilising all cores and sampling in proportion to y labels\n",
    "rfc = RandomForestClassifier(n_estimators = 500, n_jobs = -1, class_weight = 'balanced', max_depth = 6)\n",
    "boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2, perc = 95)\n",
    "boruta_selector.fit(X_np, datay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered = boruta_selector.transform(X_np)\n",
    "X_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Row Statistics for Subsetting\n",
    "One way to work with big data in biology is through data subsetting. Since individual features like genes and transcripts have no greater likelihood of being informative than any other feature. To remove features that are unlikely to be informative and to reduce the computational load of later analyses, we subset our data by easy-to-calculate metrics like variance, IQR, and mean associated deviation (MAD). Uninformative features are likely to have low values for these metrics. If we calculate the variance, IQR, and/or MAD for each transcript ID and rank each transcript ID by variance, IQR, and/or MAD, we can drastically reduce the size of the dataset by taking a fraction of the highest scorers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.stats' has no attribute 'median_absolute_deviation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-131a5eaef5d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mRow_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mrow_iqr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miqr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mrow_mad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian_absolute_deviation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mrow_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mrow_std\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'scipy.stats' has no attribute 'median_absolute_deviation'"
     ]
    }
   ],
   "source": [
    "# calculate row Var, IQR, and MAD\n",
    "# Create an empty list \n",
    " \n",
    "# turn dataframe into a 2D List full of floats\n",
    "Row_list = datax.values.T.tolist()\n",
    "for i in Row_list:\n",
    "    for j in range(len(i)):\n",
    "        i[j] = float(i[j])\n",
    "# initialize empty lists\n",
    "row_iqr = []\n",
    "row_mad = []\n",
    "row_var = []\n",
    "row_std = []\n",
    "# iterate through each row and find the Var, IQR, and MAD of each row\n",
    "for i in Row_list:\n",
    "    row_iqr.append(scipy.stats.iqr(np.asarray(i)))        \n",
    "    row_mad.append(scipy.stats.median_absolute_deviation(np.asarray(i)))\n",
    "    row_var.append(np.var(i))\n",
    "    row_std.append(np.std(i))\n",
    "\n",
    "# sort each list to be in ascending order    \n",
    "sorted_row_iqr = sorted(row_iqr)\n",
    "sorted_row_mad = sorted(row_mad)\n",
    "sorted_row_var = sorted(row_var)\n",
    "sorted_row_std = sorted(row_std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will help us visualize how are data could be subsetted.\n",
    "fig, ((ax1, ax2,ax3,ax4),(ax5,ax6,ax7,ax8)) = plt.subplots(2,4,figsize=(18,18))\n",
    "\n",
    "ax1.plot(sorted_row_iqr,color='blue')\n",
    "ax1.set_ylim([0, 4])\n",
    "ax1.title.set_text('Row Variance')\n",
    "\n",
    "\n",
    "ax2.plot(sorted_row_mad, color='orange')\n",
    "ax2.set_ylim([0, 4])\n",
    "ax2.title.set_text('Row Mean Average Deviation')\n",
    "\n",
    "ax3.plot(sorted_row_var, color='#32cd32')\n",
    "ax3.set_ylim([0, 4])\n",
    "ax3.title.set_text('Row IQR')\n",
    "\n",
    "ax4.plot(sorted_row_std, color='Pink')\n",
    "ax4.set_ylim([0, 4])\n",
    "ax4.title.set_text('Row SD')\n",
    "\n",
    "\n",
    "ax5.boxplot(sorted_row_iqr)\n",
    "\n",
    "ax6.boxplot(sorted_row_mad)\n",
    "\n",
    "ax7.boxplot(sorted_row_var)\n",
    "\n",
    "ax8.boxplot(sorted_row_std)\n",
    "\n",
    "for ax in fig.get_axes():\n",
    "    ax.label_outer()\n",
    "\n",
    "#fig.savefig(\"Row_Statistics.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "#the following function takes six parameters: the metric list (var,iqr,mad,sd lists), the sorted metric lists,the percentile as \n",
    "#an int or float, the dataset features,the string name of the metric ('iqr','var',etc.), and whether data should\n",
    "# be normalized or not\n",
    "def subset(metric_list,sorted_metric_list,percentile,datax,metric_string,norm = False):\n",
    "    #initialize empty list for column indices\n",
    "    idx_list = []\n",
    "    # determine what value of the metric is at the cutoff\n",
    "    threshold = (np.percentile(sorted_metric_list,percentile))\n",
    "    # go through the metric list and find which columns have metric values greater than or equal to the cutoff\n",
    "    for i in range(len(metric_list)):\n",
    "        if metric_list[i] >= threshold:\n",
    "            idx_list.append(i)\n",
    "    # create and return a new dataset with only the columns that have metric values \n",
    "    #greater than or equal to the cutoff\n",
    "    dataset = datax.iloc[:,idx_list]\n",
    "    if norm == True:\n",
    "        scaler = SS()\n",
    "        rownames = dataset.index\n",
    "        dataset = pd.DataFrame(scaler.fit_transform(dataset),columns = dataset.columns)\n",
    "        dataset.index = rownames\n",
    "\n",
    "    if norm == False:\n",
    "        filename = 'data_subset'+'_'+metric_string + '_' + str(percentile) + '_' + 'per.csv'\n",
    "    else:\n",
    "        filename = 'data_subset'+ '_'+ 'normalized' +'_'+metric_string + '_' + str(percentile) + '_' + 'per.csv'\n",
    "    \n",
    "    return dataset,threshold, filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, for instance, we subset the dataset features using variance and cutoff all values below the 99th percentile\n",
    "# the metric used was variance, and data was normalized (via Z scoring)\n",
    "datax_sub,threshold,filename = subset(row_var,sorted_row_var,99,datax,'var',norm=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to file\n",
    "#datax_sub.to_csv(filename)\n",
    "datax_sub.insert(0, \"Labels\", datay, True)\n",
    "labels = datax_sub.pop(\"Labels\")\n",
    "lut = dict(zip(labels.unique(), ['black','#add8e6','green','gray','gray','gray','gray']))\n",
    "row_colors = labels.map(lut)\n",
    "GWHM = sns.clustermap(datax_sub,method='centroid',xticklabels=False,yticklabels=0,row_colors=row_colors)\n",
    "\n",
    "\n",
    "for label in labels.unique():\n",
    "    GWHM.ax_col_dendrogram.bar(0, 0, color=lut[label],\n",
    "                            label=label, linewidth=0)\n",
    "GWHM.ax_col_dendrogram.legend(loc=2, ncol=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each plot shows the transcipts sorted for their ascending metric scores. A successful subset takes the metric(s) that remove most of the data but have extremely high scores for the remaining.  In this plot, variance is more informative than IQR which is more informative than MAD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn\n",
    "def BinaryTrees(dataset, labels):\n",
    "    clf = DecisionTreeClassifier(criterion = 'entropy')\n",
    "\n",
    "    clf = clf.fit(dataset, labels)\n",
    "    params = {\"max_depth\": [5,10,15,20], \"min_samples_leaf\": [5,10,15,20], \"max_features\": [5,10,15]}\n",
    "\n",
    "    grid_search = GridSearchCV(clf, params, cv = 5, scoring = 'accuracy')\n",
    "\n",
    "    grid_search.fit(dataset, labels)\n",
    "\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    print(\"Accuracy:\", grid_search.best_score_*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "def KNN(dataset, labels):\n",
    "    # Define a pipeline to search for the best combination of \n",
    "    # PCA dimensions and n_neighbors.\n",
    "    \n",
    "    #create a scaler\n",
    "    scaler = sk.preprocessing.MinMaxScaler()\n",
    "\n",
    "    #create a PCA\n",
    "    pca = PCA()\n",
    "\n",
    "    #create a KNN classifier\n",
    "    knn = KNeighborsClassifier()\n",
    "\n",
    "    #create a pipeline that does scaling, then PCA, then KNN\n",
    "    pipe = Pipeline(steps=[('scaler', scaler), ('pca', pca), ('knn', knn)])\n",
    "\n",
    "    #Set up the parameters you want to tune for each of your pipeline steps\n",
    "    #Parameters of pipelines can be set using â€˜__â€™ separated parameter names:\n",
    "    param_grid = {\n",
    "        'pca__n_components': list(range(1, 19)), #find how many principal componenet to keep\n",
    "        'knn__n_neighbors': list(range(1, 30)),  #find the best value of k\n",
    "    }\n",
    "\n",
    "    # pass the pipeline and the parameters into a GridSearchCV with a 5-fold cross validation\n",
    "    grid = GridSearchCV(pipe, param_grid, cv = 5, scoring = \"accuracy\")\n",
    "\n",
    "    # call fit() on the GridSearchCV and pass in the unscaled data (X_values, Y_values)\n",
    "    grid.fit(dataset, labels)\n",
    "\n",
    "    # print out the best_score_ and best_params_ from the GridSearchCV\n",
    "    print(\"Best Score:\", grid.best_score_ * 100)\n",
    "    print(\"Best Parameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def NaiveBayes(dataset, labels):\n",
    "    clf = GaussianNB() # set any params you may want to set\n",
    "\n",
    "# Run a 5-fold cross validation\n",
    "    scores = cross_val_score(clf, dataset, labels, cv=10) \n",
    "    print(\"Scores:\", scores)                                            \n",
    "\n",
    "    print(\"Accuracy:\", scores.mean()*100)\n",
    "    y_pred = cross_val_predict(clf, dataset, labels, cv=10)\n",
    "\n",
    "    confusion_matrix(labels,y_pred)\n",
    "    print(classification_report(labels, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def NeuralNet(dataset, labels):\n",
    "    scaler = StandardScaler()\n",
    "    mlp = MLPClassifier()\n",
    "    pipeline = Pipeline(steps=[('scaler', scaler),('mlp',mlp)])\n",
    "    param_grid = {'mlp__hidden_layer_sizes':list(range(10,61,10)),'mlp__activation':['logistic', 'tanh', 'relu']}\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "    y_pred = cross_val_score(grid_search, dataset, labels, cv=5)\n",
    "    print(y_pred.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(dataset, labels):\n",
    "    # Create StandardScaler and SVC Object\n",
    "    scaler = StandardScaler()\n",
    "    svc = SVC()\n",
    "    # Create pipeline and set steps to scaler and SVC objects\n",
    "    pipe = Pipeline(steps = [('Scaler', scaler), ('svc', svc)])\n",
    "\n",
    "    scores = cross_val_score(pipe, dataset, labels, cv = 5)\n",
    "    print('Accuracy:', scores.mean() * 100)\n",
    "    \n",
    "    # for the 'svm' part of the pipeline, tune the 'kernel' hyperparameter\n",
    "    param_grid = {'svc__kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "    # Create GridSearchCV that takes in pipeline\n",
    "    grid = GridSearchCV(pipe, param_grid, cv = 5)\n",
    "    grid.fit(dataset, labels)\n",
    "    print(\"Best kernel:\", grid.best_params_)\n",
    "    grid_score = cross_val_score(grid, dataset, labels, cv = 5, scoring = 'accuracy')\n",
    "    print('Accuracy:', grid_score.mean() * 100)\n",
    "    \n",
    "   # Create parameter grid and GridSearchCV with pipeline from above\n",
    "    params = {'svc__C': range(50, 110, 10), 'svc__kernel': ['rbf']}\n",
    "    grid_search = GridSearchCV(pipe, params, cv = 5)\n",
    "    # Pass the GridSearchCV into a cross_val_score with a 5-fold-CV \n",
    "    grid_search_score = cross_val_score(grid_search, dataset, labels, cv = 5)\n",
    "    print('Accuracy:', grid_search_score.mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "def AdaBoost(dataset, labels):\n",
    "    ada = AdaBoostClassifier()\n",
    "    param_grid = {'n_estimators':list(range(50,251,25))}\n",
    "    grid_search = GridSearchCV(ada, param_grid, cv=5, scoring = 'accuracy')\n",
    "    y_pred = cross_val_score(grid_search, dataset, labels, cv=5)\n",
    "    y_pred.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def RandomForest(dataset, labels):\n",
    "    randomForest = RandomForestClassifier()\n",
    "    param_grid = {'max_depth':list(range(35,56)), 'min_samples_leaf': [8,10,12], 'max_features':['sqrt','log2']}\n",
    "    grid_search = GridSearchCV(randomForest, param_grid, cv=5, scoring='accuracy')\n",
    "    y_pred = cross_val_score(grid_search, dataset, labels, cv=5)\n",
    "    print(y_pred.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "params_final = {'mlp__activation': ['logistic', 'tanh', 'relu'], 'mlp__hidden_layer_sizes': [(10,), (20,), (30,), (40,), (50,), (60,)]}\n",
    "pipe_final = Pipeline(steps = [('Scaler', scaler), ('mlp', mlp)])\n",
    "grid_final = GridSearchCV(pipe_final, params_final, cv = 5)\n",
    "\n",
    "# fit GridSearchCV to determine best parameters\n",
    "grid_final.fit(X_filtered, datay)\n",
    "print(\"Best Params:\", grid_final.best_params_)\n",
    "print('Accuracy:', grid_final.best_score_ * 100)\n",
    "\n",
    "#set this final_model to your final model\n",
    "final_model = grid_final\n",
    "\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(final_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BinaryTrees(X_filtered, datay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN(X_filtered, datay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveBayes(X_filtered, datay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest(X_filtered, datay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralNet(X_filtered, datay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM(X_filtered, datay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest(X_filtered, datay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoost(X_filtered, datay)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
